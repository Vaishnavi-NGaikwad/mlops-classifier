# ğŸ¾ Pet Classifier â€” MLOps Pipeline

A full end-to-end MLOps project that trains a Cat vs Dog image classifier and deploys it through a fully automated CI/CD pipeline with monitoring.

---

## ğŸ“Œ Project Overview

| Milestone | Description | Status |
|-----------|-------------|--------|
| M1 | Model Development & Experiment Tracking | âœ… |
| M2 | Model Packaging & Containerization | âœ… |
| M3 | CI Pipeline â€” Build, Test & Image Creation | âœ… |
| M4 | CD Pipeline & Deployment | âœ… |
| M5 | Monitoring, Logs & Final Submission | âœ… |

---

## ğŸ—ï¸ Architecture

```
GitHub Push
    â”‚
    â–¼
GitHub Actions CI
    â”œâ”€â”€ Run Unit Tests (pytest)
    â”œâ”€â”€ Build Docker Image
    â””â”€â”€ Push to Docker Hub
            â”‚
            â–¼
    GitHub Actions CD
        â”œâ”€â”€ Pull Image from Docker Hub
        â”œâ”€â”€ Deploy via Docker Compose
        â””â”€â”€ Run Smoke Tests
                â”‚
                â–¼
        Flask Inference Service
            â”œâ”€â”€ /health
            â”œâ”€â”€ /predict
            â”œâ”€â”€ /metrics
            â””â”€â”€ /prediction-log
```

---

## ğŸ§  Model

- **Architecture:** SimpleCNN (4 Conv layers + 3 FC layers)
- **Task:** Binary classification â€” Cat vs Dog
- **Input:** RGB image resized to 224Ã—224
- **Output:** Sigmoid score (0 = cat, 1 = dog)
- **Test Accuracy:** 70â€“80%
- **Framework:** PyTorch
- **Model file:** `simple_cnn_baseline_exp1_20260217_053749_best.pt` (299MB)
- **Stored in:** GitHub Releases v1.0

---

## ğŸ“ Project Structure

```
mlops-classifier/
â”œâ”€â”€ .dvc/                          # DVC configuration
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                 # CI/CD pipeline
â”œâ”€â”€ static/css/                    # Frontend styles
â”œâ”€â”€ templates/                     # Flask HTML templates
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py           # Unit tests (pytest)
â”œâ”€â”€ app.py                         # Flask inference service
â”œâ”€â”€ Dockerfile                     # Container definition
â”œâ”€â”€ docker-compose.yml             # Deployment manifest
â”œâ”€â”€ requirements.txt               # Pinned dependencies
â”œâ”€â”€ smoke_test.sh                  # Post-deploy smoke tests
â””â”€â”€ test_model.py                  # Model inference script
```

---

## ğŸš€ Quick Start

### Run locally with Docker Compose

```bash
docker compose up -d
```

### Or build manually

```bash
docker build -t pet-classifier .
docker run -p 5000:5000 pet-classifier
```

---

## ğŸŒ API Endpoints

### Health Check
```bash
curl http://localhost:5000/health
```
```json
{
  "status": "healthy",
  "model_loaded": true,
  "device": "cpu"
}
```

### Prediction
```bash
curl -X POST -F "file=@your_image.jpg" http://localhost:5000/predict
```
```json
{
  "success": true,
  "prediction": "dog",
  "confidence": 92.3,
  "probabilities": {
    "cat": 7.7,
    "dog": 92.3
  },
  "latency_ms": 134.5
}
```

### Metrics (M5)
```bash
curl http://localhost:5000/metrics
```
```json
{
  "total_requests": 42,
  "successful_predictions": 40,
  "failed_requests": 2,
  "average_latency_ms": 145.3
}
```

### Prediction Log (M5)
```bash
curl http://localhost:5000/prediction-log
```
```json
{
  "total_predictions": 40,
  "dog_predictions": 22,
  "cat_predictions": 18,
  "average_confidence": 87.4,
  "recent_predictions": [...]
}
```

---

## ğŸ§ª Running Tests

```bash
pip install pytest
pytest tests/test_pipeline.py -v
```

Tests cover:
- Image preprocessing output shape and normalization
- SimpleCNN forward pass output range
- Batch inference
- Model eval mode

---

## âš™ï¸ CI/CD Pipeline

Defined in `.github/workflows/ci.yml`:

**On every push to `main`:**

**Job 1 â€” CI (test-and-build):**
1. Checkout repository
2. Install dependencies
3. Run unit tests via pytest
4. Build Docker image
5. Push to Docker Hub

**Job 2 â€” CD (deploy-and-smoke-test):**
1. Pull latest image from Docker Hub
2. Deploy with Docker Compose
3. Wait for service to be ready (smart retry loop)
4. Run smoke tests (health + prediction)
5. Fail pipeline if smoke tests fail
6. Tear down containers

---

## ğŸ“Š Monitoring (M5)

The inference service includes built-in monitoring:

- **Logging:** Every request logged with timestamp, filename, prediction, confidence, and latency to both console and `app.log`
- **Request counter:** Tracks total, successful, and failed requests in memory
- **Latency tracking:** Per-request and average latency in milliseconds
- **Prediction log:** Rolling window of last 100 predictions with cat/dog distribution

---

## ğŸ”§ Environment & Dependencies

All dependencies are pinned in `requirements.txt`. Key libraries:

- `torch`, `torchvision` â€” Model inference
- `flask`, `gunicorn` â€” Web service
- `Pillow`, `numpy` â€” Image processing

---

## ğŸ³ Docker Hub

Image available at: `vaishnavi06/mlops-classifier:latest`

```bash
docker pull vaishnavi06/mlops-classifier:latest
```

---

## ğŸ‘©â€ğŸ’» Author

**Vaishnavi Gaikwad**  
MLOps Assignment â€” 2026